{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a short guide that covers issues of interest including:\n",
    "1. Defining and solving SDEs\n",
    "1. Gaining control over the randomness (path generation conditional on a Brownian motion sample)\n",
    "1. Different noise types of SDEs\n",
    "1. Gradient computation/backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchsde\n",
    "\n",
    "def plot(ts, samples, xlabel, ylabel, title=''):\n",
    "    plt.figure()\n",
    "    for i, sample in enumerate(samples):\n",
    "        plt.plot(ts, sample, marker='x', label=f'sample {i}')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like how each ordinary differential equation (ODE) is governed by a vector field, a stochastic differential equation (SDE) is governed by two vector fields, which are called the **drift** and **diffusion** functions:\n",
    "$$dy(t) = \\underbrace{f(t, y(t), \\theta_f)}_{\\text{drift}} dt + \\underbrace{g(t, y(t), \\theta_g)}_{\\text{diffusion}} dW(t).$$\n",
    "The output of $f$ is of the same size as the $d$-dimensional state, whereas the output of $g$ may be a matrix of size $(d, m)$. \n",
    "\n",
    "Here, $W(t)$ is the Brownian motion (aka Wiener process), and it may be $m$ dimensional. It is a stochastic process, and each random draw produces a function of time. \n",
    "\n",
    "### 1. Solving a simple SDE\n",
    "To implement an SDE, we create a class with the functions `f` and `g`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Parameter(torch.tensor(0.1), requires_grad=True)  # Scalar parameter.\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "    \n",
    "    def f(self, t, y):\n",
    "        return torch.sin(t) + self.theta * y\n",
    "    \n",
    "    def g(self, t, y):\n",
    "        return 0.3 * torch.sigmoid(torch.cos(t) * torch.exp(-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions `f` and `g` are arbitrarily chosen for demonstration purposes. The attributes `noise_type` and `sde_type` are used in the solver to determine the particular numerical method being used and must be included. We use `diagonal` here, meaning the output of `g` should be a vector with the same shape as input `y`, and it is an element-wise function. \n",
    "Note that for any other noise type, we expect the output of `g` to be a matrix, and batch matrix-vector product is performed under the hood.\n",
    "The requirement of element-wise function is a rather technical condition to ensure the high-order solvers attain their theoretically derived efficiency. \n",
    "\n",
    "The codebase supports both Itô SDEs based on [Itô integrals](https://en.wikipedia.org/wiki/It%C3%B4_calculus) and Stratonovich SDEs based on [Stratonovich integrals](https://en.wikipedia.org/wiki/Stratonovich_integral).\n",
    "\n",
    "Now we instantiate an object of the SDE class and call the function `sdeint` on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, state_size, t_size = 3, 1, 100\n",
    "sde = SDE()\n",
    "ts = torch.linspace(0, 1, t_size)\n",
    "y0 = torch.full(size=(batch_size, state_size), fill_value=0.1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ys = torchsde.sdeint(sde, y0, ts, method='euler')  # (t_size, batch_size, state_size) = (100, 3, 1).\n",
    "\n",
    "plot(ts, ys.squeeze().t(), xlabel='$t$', ylabel='$Y_t$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Itô SDEs `method='euler'` means the strong order 0.5 Euler-Maruyama method is used. Other possible methods include the strong order 1.0 `milstein` and the strong order 1.5 `srk`, both of which are of slightly higher order. If `method` is set to `None`, an appropriate solver would be chosen based on `noise_type` and `sde_type` under the hood.\n",
    "\n",
    "To solve a Stratonovich SDE with drift and diffusion defined above, we need only change `sde_type` to `stratonovich`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sde.sde_type = \"stratonovich\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    ys = torchsde.sdeint(sde, y0, ts, method=\"midpoint\")  # (t_size, batch_size, state_size) = (100, 3, 1).\n",
    "\n",
    "plot(ts, ys.squeeze().t(), xlabel='$t$', ylabel='$Y_t$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Stratonovich SDEs, the methods `midpoint`, `euler_heun`, `heun`, `milstein`, and `log_ode` are supported. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drift and diffusion functions don't necessarily need to be defined as the `f` and `g` methods of the class. They can be methods with any name, so long as we provide these names to the solver when they differ from the default `f` and `g`. The following is an example where `h` is used as the drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDENewName(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Parameter(torch.tensor(0.1), requires_grad=False)  # Scalar parameter.\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "    \n",
    "    def h(self, t, y):\n",
    "        return torch.sin(t) + self.theta * y\n",
    "    \n",
    "    def g(self, t, y):\n",
    "        return 0.3 * torch.sigmoid(torch.cos(t) * torch.exp(-y))\n",
    "    \n",
    "sde_new_name = SDENewName()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Supply a dictionary to the argument `names`.\n",
    "    ys = torchsde.sdeint(sde_new_name, y0, ts, method='euler', names={'drift': 'h'})\n",
    "\n",
    "plot(ts, ys.squeeze().t(), xlabel='$t$', ylabel='$Y_t$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trivially, the previous code may be adapted to run on GPUs, just by moving all tensors to a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu = torch.device('cuda')\n",
    "    sde = SDE().to(gpu)\n",
    "    ts = ts.to(gpu)\n",
    "    y0 = y0.to(gpu)\n",
    "    with torch.no_grad():\n",
    "        ys = torchsde.sdeint(sde, y0, ts, method='euler')  # (100, 3, 1).\n",
    "    \n",
    "    plot(ts.cpu(), ys.squeeze().t().cpu(), xlabel='$t$', ylabel='$Y_t$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A side note is that multi-GPU data parallel is possible with the existing codebase, but the use case has not been tested out extensively and may require defining non-standard SDE classes and methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explicit control over randomness from the Brownian motion\n",
    "To gain control over the randomness, we draw Brownian motion samples by instantiating objects of classes `BrownianInterval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = torch.linspace(0, 1, t_size)\n",
    "bm = torchsde.BrownianInterval(t0=0.0, t1=1.0, size=(batch_size, state_size))\n",
    "\n",
    "bm_increments = torch.stack([bm(t0, t1) for t0, t1 in zip(ts[:-1], ts[1:])], dim=0)\n",
    "bm_queries = torch.cat((torch.zeros(1, batch_size, state_size), torch.cumsum(bm_increments, dim=0)))\n",
    "\n",
    "plot(ts, bm_queries.squeeze().t(), xlabel='$t$', ylabel='$W_t$', title='Query')\n",
    "\n",
    "bm_increments2 = torch.stack([bm(t0, t1) for t0, t1 in zip(ts[:-1], ts[1:])], dim=0)\n",
    "bm_queries2 = torch.cat((torch.zeros(1, batch_size, state_size), torch.cumsum(bm_increments2, dim=0)))\n",
    "plot(ts, bm_queries.squeeze().t(), xlabel='$t$', ylabel='$W_t$', \n",
    "     title='Query again (samples should be same as before)')\n",
    "\n",
    "assert torch.allclose(bm_queries, bm_queries2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create the Brownian motion on GPUs by specifying `device`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    bm = torchsde.BrownianInterval(t0=0.0, t1=1.0, size=(batch_size, state_size), device=gpu)\n",
    "    print(bm(0.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a Brownian motion object helps us gain control over the randomness better. We can feed the object into the solver such that the solver's solution is conditioned on this path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sde = SDE()\n",
    "ts = torch.linspace(0, 1, t_size)\n",
    "y0 = torch.zeros((batch_size, 1)).fill_(0.1)  # (batch_size, state_size).\n",
    "bm = torchsde.BrownianInterval(t0=0.0, t1=1.0, size=(batch_size, state_size))\n",
    "\n",
    "with torch.no_grad():\n",
    "    ys = torchsde.sdeint(sde, y0, ts, method='milstein', bm=bm)\n",
    "plot(ts, ys.squeeze().t(), xlabel='$t$', ylabel='$Y_t$', title='Solve SDE')\n",
    "\n",
    "with torch.no_grad():\n",
    "    ys = torchsde.sdeint(sde, y0, ts, method='milstein', bm=bm)\n",
    "plot(ts, ys.squeeze().t(), xlabel='$t$', ylabel='$Y_t$', \n",
    "     title='Solve SDE again (samples should be same as before)')\n",
    "\n",
    "# Use a new BM sample, we expect different sample paths.\n",
    "bm = torchsde.BrownianInterval(t0=0.0, t1=1.0, size=(batch_size, state_size))\n",
    "with torch.no_grad():\n",
    "    ys = torchsde.sdeint(sde, y0, ts, method='milstein', bm=bm)\n",
    "plot(ts, ys.squeeze().t(), xlabel='$t$', ylabel='$Y_t$', \n",
    "     title='Solve SDE (expect different sample paths)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Noise type of SDEs affects which solvers can be used and what strong orders can be attained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supported noise types of this codebase are \"diagonal\", \"additive\", \"scalar\", and \"general\".\n",
    "The following is a simple summary of each type:\n",
    "- \"diagonal\": The diffusion function is an elementwise function, with the output being the same dimension as the state (both $d$-dimensional). There are $d$ independent Brownian motions, each responsible for the noise of only a single state dimension.\n",
    "- \"additive\": The diffusion function is a constant w.r.t. the state, i.e. the derivative of the diffusion function w.r.t. the state is 0. The output of the diffusion function is of size $(d, m)$, and the system has $m$ independent Brownian motions. The integral involving the Brownian motion can be loosely interpreted as integrating a sequence of matrix-vector products.\n",
    "- \"scalar\": The diffusion function has output shape $(d, 1)$, and a single Brownian motion is shared across all state dimensions. \n",
    "- \"general\": The diffusion function has output shape $(d, m)$, and the system has $m$ independent Brownian motions.\n",
    "\n",
    "It is tempting to use the noise type configuration \"general\" for all problems. However, since there's little known structure for these SDEs, solvers with high strong-order cannot be constructed.\n",
    "\n",
    "Lastly, for modeling problems, our limited experience have found \"diagonal\" to be a good setting, where flexibility of models and tractability of numerical integration is rather well-balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Computing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing gradients through SDE solutions can be easily done by calling the `backward` function on loss tensors, or using `torch.autograd.grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = torchsde.sdeint(sde, y0, ts, method='euler', bm=bm)\n",
    "y_final = ys[-1]\n",
    "target = torch.randn_like(y_final)\n",
    "loss = ((target - y_final) ** 2).sum(dim=1).mean(dim=0)\n",
    "loss.backward()\n",
    "print(sde.theta.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = torchsde.sdeint(sde, y0, ts, method='euler', bm=bm)\n",
    "y_final = ys[-1]\n",
    "target = torch.randn_like(y_final)\n",
    "loss = ((target - y_final) ** 2).sum(dim=1).mean(dim=0)\n",
    "grad, = torch.autograd.grad(loss, sde.theta)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching to adjoint-mode gradient computation is as simple as replacing `sdeint` with `sdeint_adjoint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = torchsde.sdeint_adjoint(sde, y0, ts, method='euler', bm=bm)\n",
    "y_final = ys[-1]\n",
    "target = torch.randn_like(y_final)\n",
    "loss = ((target - y_final) ** 2).sum(dim=1).mean(dim=0)\n",
    "loss.backward()\n",
    "print(sde.theta.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
